\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,sectsty,comment,natbib,footmisc,pdflscape,subfigure,array,hyperref,booktabs,hypcap,siunitx,threeparttable,rotating,longtable,booktabs}


\normalem

\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}

\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}

\begin{document}

\begin{titlepage}
\title{Recovering Predictability from the Implied Volatility Surface: A Vision Transformer Approach\thanks{abc}}
% \author{Zhenqi Hu\thanks{abc}}
\date{\today}
\maketitle
\begin{abstract}
\noindent Placeholder\\
\vspace{0in}\\
\noindent\textbf{Keywords:} key1, key2, key3\\
\vspace{0in}\\
\noindent\textbf{JEL Codes:} key1, key2, key3\\

\bigskip
\end{abstract}
\setcounter{page}{0}
\thispagestyle{empty}
\end{titlepage}
\pagebreak \newpage




\doublespacing


\section{Introduction} \label{sec:introduction}

\section{Literature Review} \label{sec:literature}

\section{Data} \label{sec:data}
\subsection{Option-Implied Volatility Surface (IVS)} \label{sec:ivs}
We obtain the equity and index option data from the IvyDB OptionMetrics database, which provides Volatility Surface files (vsurfdYYYY) that contain the interpolated Black-Scholes implied volatilities, starting from January 1996. For each security on each day, a volatility surface with standard maturities of $\tau$ days to expiration and moneyness levels measured by option $\delta$ is provided. \footnote{OptionMetrics use a methodology based on a kernel smoothing algorithm to interpolate the volatility surface. The maturities are 10, 30, 60, 91, 122, 152, 182, 365, 547, 730 days to expiration, and the option delta levels are from 0.1 to 0.9 with a step of 0.05, positive for call options and negative for put options.}

We select out-of-the-money (OTM) and near at-the-money (ATM) put options with delta levels in [-0.5, -0.1], as well as OTM and near ATM call options with delta levels in [0.1, 0.5], since the deep-in-the-money call options are often illiquid, following \citet{martinWhatExpectedReturn2017}, among others. The options are rearranged by their moneyness (implied strike), so the delta levels start from -0.1 to -0.5, then from 0.5 to 0.1 \footnote{The implied strike order between put option with delta -0.5 and call option with delta 0.5 is uncertain, but their spread is proved to have predictive power for future returns \citep{yanJumpRiskStock2011}, so we keep both of them.}. We also drop the options with maturities equal to 10 days, since the large fraction of missing values. The final volatility surface data contains 10 maturities and 18 delta levels, and a example of the volatility surface is shown in Figure \ref{fig:vsurf_3d_plot}. The input features, in result, can be represented as $IV_{i, t} = \{IV_{i,t}(\tau, \delta)\}_{\tau \in T, \delta \in \Delta}$. the volatility surface of security $i$ at time $t$.


We obtain the daily return data from CRSP for all firms listed on NYSE, AMEX, and NASDAQ, as well as the S$\&$P 500 index. For each security $i$ at time $t$, we calculate the cumulative return on security $i$ from day $t$ to day $t+H$ as:
\begin{align}
    r_{i,t}^H = \prod_{j=0}^{H-1} (1 + r_{i,t+j}) - 1
\end{align}

We link the volatility surface data from OptionMetrics with the return data from CRSP using a linking table provided by WRDS. The final dataset spans from January 1996 to August 2023, and Figure \ref{fig:num_stocks_vsurf} shows the coverage of the stocks with available volatility surface data over time. The number of stocks with available volatility surface data increases significantly over time, from below 1000 to over 5000 in recent years.

\subsection{Option Characteristics} \label{sec:opt_char}
Motivated by the extensive literature from cross-section studies of stock returns, we also collect a set of option-related characteristics that have been shown to have predictive power for future stock returns. \citet{neuhierlOptionCharacteristicsCrosssectional2022} summarized a comprehensive list of option characteristics and compared their performance. We follow their results and select the strongest predictors, which are described in the Appendix \ref{sec:appendixb}.


\section{The Vision Transformer Model} \label{sec:model}
In this section, we briefly introduce the vision transformer (ViT) model architecture and our experimental design.

\subsection{Brief Introduction of the Vision Transformer Model} \label{sec:transformer}
First introduced by \citet{vaswaniAttentionAllYou2017}, "Attention Is All You Need," the Transformer model has become a foundational architecture in deep learning, particularly for natural language processing (NLP). Unlike its predecessors, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, the Transformer does not rely on sequential data processing. Instead, it processes the entire input sequence at once, using a sophisticated mechanism known as self-attention to weigh the importance of different words in the sequence.

The core of the Transformer is its encoder-decoder structure. The encoder's role is to map an input sequence of symbol representations $(x_1, ..., x_n)$ to a sequence of continuous representations $z=(z_1,...,z_n)$. The decoder then takes $z$ and generates an output sequence $(y_1,...,y_m)$, one symbol at a time.

Building on the success of the Transformer in NLP, the Vision Transformer (ViT) was proposed by \citet{dosovitskiyImageWorth16x162020} to apply the same architecture to computer vision tasks, offering a compelling alternative to the widely used Convolutional Neural Networks (CNNs). The fundamental idea behind ViT is to treat an image as a sequence of patches, analogous to how a sentence is treated as a sequence of words.

By converting images into a sequential format, ViT demonstrates that the reliance on convolutions is not a necessity for vision tasks and that a general-purpose attention-based architecture can achieve state-of-the-art (SOTA) performance, especially when pre-trained on large datasets.

The architecture of the ViT, shown in Figure \ref{fig:vit_figure}, adapts the original Transformer in the following way:
\begin{enumerate}
    \item \textbf{Image Patching and Embedding}: The ViT model first reshapes the input image from a 2D grid of pixels into a sequence of flattened 2D patches. For a image $x \in \mathbb{R}^{H\times W \times C}$, it is divided into $N$ patches $x_p \in \mathbb{R}^{N \times (P^2 \cdot C)}$, where $(H, W)$ is the height and width of the original image, $C$ is the number of channels (e.g., RGB), and $(P, P)$ is the resolution of each patch, and $N = (H \times W) / (P^2)$ is the number of patches. These patches are then flattened and mapped to a latent D-dimensional embedding space through a trainable linear projection. Each patch is taken as a token, similar to words in NLP.
    \item \textbf{Learnable Class Token}: Inspired by the [CLS] token used in BERT (Bidirectional Encoder Representations from Transformers) model \citep{devlinBERTPretrainingDeep2019}, a learnable embedding is prepended to the sequence of patch embeddings. The state of this token at the output of the Transformer encoder serves as the aggregate image representation for classification tasks.
    \item \textbf{Positional Embeddings}: Similar to the positional encodings in the original Transformer, the ViT adds learnable 1D positional embeddings to the patch embeddings to retain spatial information. These embeddings allow the model to learn the relative positions of the image patches.
    
    The flattened patches, along with the class token and positional embeddings, are served as input to the Transformer encoder:
    \begin{align}
        \mathbf{z}_0 = [\mathbf{x}_{class}; \mathbf{x}_p^1 E; \mathbf{x}_p^2 E; ...; \mathbf{x}_p^N E] + E_{pos}
    \end{align}
    where $E \in \mathbb{R}^{(P^2 \cdot C) \times D}$ is the patch embedding projection matrix, $E_{pos} \in \mathbb{R}^{(N+1) \times D}$ is the positional embedding matrix, and $\mathbf{z}_0 \in \mathbb{R}^{(N+1) \times D}$ is the resulting sequence of embedded patches, with length $N+1$ (including the class token) and embedding dimension $D$.

    \item \textbf{Transformer Encoder}: The resulting sequence of embedded patches (including the class token) is then fed directly into a standard Transformer encoder \citep{vaswaniAttentionAllYou2017}. This encoder is composed of alternating layers of multi-head self-attention (MSA) and multi-layer perceptron (MLP) blocks, similar to the original Transformer encoder, but with some slight modifications:
    \begin{itemize}
        \item \textbf{Multi-Head Self-Attention (MSA)}: This mechanism allows the model to focus on different parts of the input sequence simultaneously, capturing various aspects of the image. Each attention head computes a weighted sum of the input embeddings, where the weights are determined by the similarity between the query and key vectors. These similarity scores are calculated using Query (Q), Key (K), and Value (V) matrices, which are linear projections of the input embeddings. The attention scores are computed as:
        \begin{align}
            \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
        \end{align}
        where $d_k$ is the dimension of the key vectors, used for scaling. The multi-head attention mechanism allows the model to jointly attend to information from different representation subspaces at different positions.
        For layer $l = 1,...,L$, the MSA block can be expressed as:
        \begin{align}
            \mathbf{z}_l' = \text{MSA}(LN(\mathbf{z}_{l-1})) + \mathbf{z}_{l-1}
        \end{align}
        where $LN(\cdot)$ denotes layer normalization, and $\mathbf{z}_l' \in \mathbb{R}^{(N+1) \times D}$ is the output of the MSA block at layer $l$.
        \item \textbf{Multi-Layer Perceptron (MLP)}: Following the MSA, a position-wise feed-forward network (FFN) is applied to each position independently and identically. This FFN typically consists of two linear layers with a Gaussian Error Linear Unit (GELU) activation in between, unlike the Rectified Linear Unit (ReLU) used in the original Transformer:
        \begin{align}
            \text{MLP}(x) = \text{GELU}(xW_1 + b_1)W_2 + b_2
        \end{align}
        where $W_1, W_2$ are weight matrices and $b_1, b_2$ are bias vectors. Besides, dropout is applied after each fully connected layer to prevent overfitting.
        For layer $l = 1,...,L$, the MLP block can be expressed as:
        \begin{align}
            \mathbf{z}_l = \text{MLP}(LN(\mathbf{z}_l')) + \mathbf{z}_l'
        \end{align}
        where $\mathbf{z}_l \in \mathbb{R}^{(N+1) \times D}$ is the output of the MLP block at layer $l$.
        \item \textbf{Layer Normalization}: In contrast to the post-normalization used in the original Transformer, the encoder blocks in ViT implement pre-normalization, where layer normalization is applied right before the MSA and MLP blocks, which has been shown to lead to mre effective training for deeper networks \citep{xiongLayerNormalizationTransformer2020} without the need for learning rate warm-up.
    \end{itemize}
    
    \item \textbf{Classification Head}: For image classification, only the output vector
    corresponding to the prepended class token in the final layer ($\mathbf{z}_L^0$) is used, which serves as the aggregate representation of the entire image:
    \begin{align}
        \mathbf{v} = LN(\mathbf{z}_L^0)
    \end{align} 
    This vector $\mathbf{v} \in \mathbb{R}^{D}$, which serves as an encoded vector representation of the input image, is then passed through a final classification head, typically a single linear layer followed by a softmax function, to produce the class probabilities:
    \begin{align}
        \mathbf{y} = \text{softmax}(\mathbf{v}W_c + b_c)
    \end{align}
    where $W_c \in \mathbb{R}^{D \times K}$ and $b_c \in \mathbb{R}^{K}$ are the weights and bias of the classification head, and $K$ is the number of classes.
\end{enumerate}

\subsection{Image Representation of Option-Implied Volatility Surface} \label{sec:embedding}
In the computer vision (CV) field, a image is typically represented as a three-dimensional matrix with $(C, H, W)$ dimensions, where $C$ is the number of channels (e.g., $C=3$ for RGB images, and $C=1$ for grayscale images), $H$ is the height (number of pixels in vertical direction), and $W$ is the width (number of pixels in horizontal direction). Each pixel in the image has a value ranging from 0 to 255, representing the intensity of the color channel(s) at that pixel.

An option-implied volatility surface is a three-dimensional plot that displays the implied volatility of a security options across different strike prices and expirations (Figure \ref{fig:vsurf_3d_plot}). As shown in Figure \ref{fig:vsurf_heatmap}, the volatility surface can also be represented as a two-dimensional matrix, which is anlogous to a single-channel grayscale image. The height $H$ of the matrix corresponds to the number of maturities $N_{\tau}$, and the width $W$ corresponds to the number of moneyness levels $N_{\delta}$. In our dataset (described in Section \ref{sec:data}), the volatility surface contains 10 maturities and 18 moneyness levels, so we can reshape the volatility surface into a "image-like" matrix with dimensions $(C, H, W) = (1, 10, 18)$. The pixel values in the matrix are the corresponding implied volatility levels, which are standardized to have zero mean and unit variance before being fed into the ViT model, just like standard image preprocessing in the computer vision field.

Besides the implied volatility surface of individual stocks, we also consider the implied volatility surface of the S$\&$P 500 index options as an additional input. The index options contain essential information of market-wide risk and risk premia, in time series as well as in cross-section, providing incremental predictive power for the stock returns \citep{andersenRiskPremiaEmbedded2015,angCrossSectionVolatilityExpected2006}. The index volatility surface, in hence, can serve as an additional channel for the input volatility surface "image". However, unlike standard RGB images, where the three channels (Red, Green, Blue) contain correlated and complementary information about the same object, the two implied volatility surfaces in our case contain semantically distinct and independent information. This poses a challenge for the standard ViT model, which is designed to process images with correlated channels. Inspired by \cite{baoChannelVisionTransformers2024}, we use the so-called Channel ViT model for the embedding of the multiple volatility surfaces. 

Specifically, the Channel ViT model, shown in Figure \ref{fig:channel_vit_figure}, processes each input channel (volatility surface) independently in the embedding stage. Each channel (volatility surface) is split into patches, linearly embedded, and employs a set of learnable channel embeddings to encode the channel-specific information besides the positional embeddings. The resulting sequence of vectors from all channels is then concatenated and fed into a standard Transformer encoder, similar to the original ViT model. Since the two volatility surfaces have the exactly the same structure (same maturities and moneyness levels), they share a common positional encoding matrix.

The ViT model, except for the final classification head, can be viewed as a non-linear mapping $ViT(\cdot | \theta)$ from the input image (volatility surface) to a dense vector representation of the image: 
\begin{align}
    \mathbf{v}_{i, t} = \mathbf{ViT}(IV_{t} | \theta)
\end{align}
Where $IV_{t} = IV_{i, t}$ or $IV_{t} = (IV_{i, t}, IV_{spx, t})$ depending on whether we use single or multiple volatility surfaces as input. Here, $IV_{i, t}$ is the volatility surface of stock $i$ at time $t$, and $IV_{spx, t}$ is the volatility surface of the S$\&$P 500 index at time $t$. $\mathbf{v}_{i, t} \in \mathbb{R}^{D}$ is vector representation of the information contained in the volatility surfaces, and $\theta$ is the set of parameters of the ViT model, excluding the final classification head.

\subsection{Discretization of Return} \label{sec:classification}

Utilizing the dense vector representation $\mathbf{v}_{i, t}$ obtained from the ViT model, a classification head is attached to perform classification tasks. In our study, such a classification head is a single linear layer followed by a softmax function \footnote{In the original ViT paper, \citet{dosovitskiyImageWorth16x162020} used a multi-layer perceptron (MLP) with one hidden layer at pre-training time and used a single linear layer at fine-tuning time. A recent update, \citet{beyerBetterPlainViT2022} from some of the same authors of the original paper suggests that a simple linear layer at the end is not significantly worse than an MLP. We use a single linear layer for simplicity reason.}, which maps the vector representation $\mathbf{v}_{i, t}$ to a probability distribution over the classes:
\begin{align}
\mathbf{p}_{i,t} &= \text{softmax}(W_c \cdot \mathbf{v}_{i, t} + b_c) \\
\text{softmax}(\mathbf{x})_j &= \frac{e^{x_j}}{\sum_{k=1}^{K} e^{x_k}}, \quad j = 1, ..., K
\end{align}
where $W_c \in \mathbb{R}^{K \times D}$ and $b_c \in \mathbb{R}^{K}$ are the weights and bias of the classification head, and $K$ is the number of classes. The output $\mathbf{p}_{i,t} \in \mathbb{R}^{K}$ is a probability vector, where each element $\mathbf{p}_{i,t}(k)$ represents the predicted probability of stock $i$'s return falling into class $k$ at time $t$.

The simplest classification is the binary classification, where the number of classes $K=2$. For example, we can classify the stock return into "up" and "down" classes based on whether the future return is positive or negative, as in \citet{jiangReImaginingPriceTrends2023}. Alternatively, the stock return can be classified into "safe" and "crash" classes based on whether the future return is above a certain negative value (e.g., -10\%). In general, we denote $y_{i, t}$ as the binary variable indicating whether stock $i$'s return falls into the two classes defined by a specific threshold $q$ at time $t$:
\begin{align}
    y_{i, t} &= \mathbf{I}(r_{i,t}^H > q) =
    \begin{cases}
    1, & \text{if } r_{i,t}^H > q \\
    0, & \text{if } r_{i,t}^H \leq q
    \end{cases} \\
    \hat{y}_{i,t} &= \mathbf{p}_{i,t}(1)
\end{align}
where $r_{i,t}^H$ is the cumulative return of stock $i$ from day $t$ to day $t+H$, and the output $\hat{y}_{i,t} = \mathbf{p}_{i,t}(1)$ represents the predicted probability of stock $i$'s return being in class 1 at time $t$.  The threshold $q$ can be set to 0 for the "up/down" classification. \footnote{In the special case of binary classification ($K=2$), the softmax function reduces to the logistic (sigmoid) function.}

For multi-class classification ($K > 2$), the stock returns can be discretized into multiple classes based on quantiles or specific thresholds. Assume $\{q_0, q_1, ..., q_K\}$ are the thresholds that define the $K$ classes, where $q_0 = -\infty$ and $q_K = +\infty$. In general, we denote $y_{i, t}$ as the categorical variable indicating which class stock $i$'s return falls into at time $t$:
\begin{align}
    y_{i, t} &= k, \quad \text{if } r_{i,t}^H \in (q_{k-1}, q_k], \quad k = 1, 2, ..., K \\
    \hat{y}_{i,t}^k &= \mathbf{p}_{i,t}(k)
\end{align}

\subsection{Training Process} \label{sec:training}
We use standard cross-entropy loss function for the classification task. For binary classification, where $y \in \{0, 1\}$, the loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \left[y \log(\hat{y}) + (1-y) \log(1-\hat{y})\right]
\end{align}

For multi-class classification, where $y \in \{1, 2, ..., K\}$, the loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \sum_{k=1}^{K} \mathbf{I}(y = k) \log(\hat{y}^k)
\end{align}
where $\hat{y}^k$ is the predicted probability of class $k$.

In the case of imbalanced classes, we can use a weighted cross-entropy loss function to give more importance to the minority classes. The weighted loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \sum_{k=1}^{K} w_k \cdot \mathbf{I}(y = k) \log(\hat{y}^k) \\
    w_k &= \frac{N}{K \cdot N_k}
\end{align}
where $w_k$ is the weight for class $k$, $N$ is the total number of samples, and $N_k$ is the number of samples in class $k$. This weighting scheme helps to balance the influence of each class during training, especially when some classes are underrepresented.

We adopt similar regularization techniques as in \citet{guEmpiricalAssetPricing2020}, to prevent overfitting and improve the comuputational efficiency. We use a Adaptive Moment Estimation With Weight Decay (AdamW) optimizer \citep{loshchilovDecoupledWeightDecay2019}, which is standard in the transformer training and a refined version of the Adam optimizer \citep{kingmaAdamMethodStochastic2017}. AdamW decouples the weight decay (L2 regularization) from the gradient update, which has been shown to lead to better generalization performance. In this study, we set the learning rate to $1\times 10^{-5}$, the weight decay to $1\times 10^{-2}$ and the batch size to 512. We use a dropout rate of $0.2$ to prevent overfitting. Dropout is a regularization technique that randomly sets a fraction of the input units to zero during training, which helps prevent overfitting by reducing the model's reliance on specific features. 

We apply multiple methods for parameter initialization: for weights in the patch embedding layers and classfication head, we use the Xavier initialization \citep{glorotUnderstandingDifficultyTraining2010}, which is the best practice for deep neural networks such as CNNs; for parameters in the CLS token and positional embeddings, as well as the weights in the Transformer encoder, we use a truncated normal distribution with a standard deviation of $0.02$, following the BERT model \citet{devlinBERTPretrainingDeep2019}; for layer normalization parameters, we initialize the weights to 1; the biases in all layers are initialized to 0. We use a standard "warm-up" and "cosine decay" learning rate scheduler, which gradually increases the learning rate from zero to the initial value over a specified number of warm-up steps, and then decays it using a cosine function. This approach helps stabilize training in the early stages and allows for better convergence. Early stopping is also employed, where the training process is halted if the validation loss does not improve for a two consecutive epochs, to prevent overfitting and save computational resources.

We train each model using annually updated rolling window, given the time-varying universe of stocks in \ref{fig:num_stocks_vsurf}. Specifically, we use a 8-year in-sample period, with 6 years for training and 2 years for validation, to predict the out-of-sample returns for the subsequent year. The first training period starts from January 1996 to December 2003, and the trained model is then used to predict out-of-sample returns for the subsequent year 2004. The model is then updated with the data from 2004, and used to predict out-of-sample returns for 2005. This process continues until August 2023, the last month of our dataset. Overall, the out-of-sample prediction period is from January 2004 to August 2023, which contains around 20 years of results. The daily dataset provides a large number of training samples, which is crucial for training such a large deep learning model, while we only collect the out-of-sample predictions at the end of each month for empirical analysis. Since the stochastic nature of the Vision Transformer model, we train each specific model for five times and calculate the average predictions, following \citet{guEmpiricalAssetPricing2020}.

\section{Empirical Results} \label{sec:result}
We begin with the simplest binary classification problem ($K = 2$). Following \citet{jiangReImaginingPriceTrends2023}, the stock returns are simply classified into "up" and "down" classes based on whether the future return is positive or negative. Besides the simplicity and interpretability, one remarkable benefit of such binary classification is that the two classes are naturally more balanced in our dataset, which is to say, there are approximately $50\%$ "up" labels and $50\%$ "down" labels. This is crucial for the training of such deep learning or machine learning models, since imbalanced classes can lead to suboptimal performance, as the model may become biased towards the majority class \citep{heLearningImbalancedData2009a}.

We focus on the prediction of 1-month ahead stock returns ($H=21$ trading days), which is common in the literature of cross-section of stock returns studies. Table \ref{tab:portfolio_binary_full} reports the portfolio performance of equal-weight and value-weight decile portfolios, including a long-short spread portfolio "H-L", formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ in each month's end, with a holding period of one month. The table 

\section{Conclusion} \label{sec:conclusion}



\singlespacing
\setlength\bibsep{0pt}


\clearpage

\onehalfspacing
\bibliographystyle{rfs}
\bibliography{ref}
\clearpage

\section*{Tables} \label{sec:tab}
\addcontentsline{toc}{section}{Tables}


\begin{table}[htbp]
\centering
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)},
    input-open-uncertainty = {(},
    input-close-uncertainty = {)}
}
\setlength{\tabcolsep}{3pt}
\caption{Portfolio Analysis, Binary Classification Model, All Stocks}
\label{tab:portfolio_binary_full}
\begin{threeparttable}
\input{Tables/portfolio_binary_models.tex}
\begin{tablenotes}
    \footnotesize
    \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
\end{tablenotes}
\end{threeparttable}
\end{table}

% \clearpage
% \begin{sidewaystable}[htbp]
% \centering
% \setlength{\tabcolsep}{4pt}
% \small
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Correlation Analysis, Binary Classification Model, All Stocks}
% \input{Tables/corr_binary.tex}
% \label{tab:corr_binary}
% \end{sidewaystable}


\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Correlation Analysis}
\label{tab:corr_binary_models}
\begin{threeparttable}
\input{Tables/corr_binary_models.tex}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{4pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Portfolio Characteristics, Binary Classification Model, All Stocks}
\label{tab:port_char_binary}
\begin{threeparttable}
\input{Tables/port_char_binary.tex}
\end{threeparttable}
\end{table}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)}
}
\caption{Time Series Regression, Binary Classification Model, All Stocks}
\label{tab:ts_reg_binary_models}
\begin{threeparttable}
\input{Tables/ts_reg_binary_models.tex}
\end{threeparttable}
\end{table}

% \begin{table}[htbp]
% \centering
% \setlength{\tabcolsep}{2pt}
% \small
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)}
% }
% \caption{Time Series Regression, Binary Classification Model, All Stocks}
% \label{tab:ts_reg_binary_models_alt}
% \begin{threeparttable}
% \input{Tables/ts_reg_binary_models_alt.tex}
% \end{threeparttable}
% \end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{3pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Fama-MacBeth Regression, Binary Classification Model, All Stocks}
\label{tab:fm_reg_binary_full}
\begin{threeparttable}
\input{Tables/fm_reg_binary_models.tex}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Logistic Regression, Future Stock Return}
\label{tab:logistic_reg_binary_full}
\begin{threeparttable}
\input{Tables/logistic_reg_binary_full.tex}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{1pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Logistic Regression, Future Stock Crash}
\label{tab:logistic_reg_crash_full}
\begin{threeparttable}
\input{Tables/logistic_reg_crash_full.tex}
\end{threeparttable}
\end{table}

\clearpage

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Summary Statistics of K-Means Clustering, 100 Clusters}
\label{tab:kmeans100_summary_stats}
\begin{threeparttable}
\input{Tables/kmeans100_summary_stats.tex}
\end{threeparttable}
\end{table}


\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{2pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Portfolio Returns, K-Means Clustering}
\label{tab:portfolio_kmeans_mu_s}
\begin{threeparttable}
\input{Tables/portfolio_kmeans.tex}
\begin{tablenotes}
    \footnotesize
    \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
\end{tablenotes}
\end{threeparttable}
\end{table}

\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Cross-Sectional Regression, K-Means Clustering, 100 Clusters}
\label{tab:cs_reg_beta}
\begin{threeparttable}
\input{Tables/cs_reg_beta.tex}
\end{threeparttable}
\end{table}

\clearpage



% ------------------------------- Figures ------------------------------- %

\section*{Figures} \label{sec:fig}
\addcontentsline{toc}{section}{Figures}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{Figures/num_stocks_vsurf.png}
    \caption{Number of Stocks with Option-Implied Volatility Surface Data (1996-2023). The figure shows the number of stocks with available option-implied volatility surface data from IvDB OptionMetrics, spanning from January 1996 to August 2023.}
    \label{fig:num_stocks_vsurf}
    
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vsurf_3d_plot.png}
    \caption{Example of Interpolated Option-Implied Volatility Surface (AAPL, 01/08/2023). The plot shows the volatility surface for Apple Inc. (AAPL) on Aug 1st, 2023, with moneyness (option delta) on the x-axis, days to expiration on the y-axis, and implied volatility levels represented by the color gradient.}
    \label{fig:vsurf_3d_plot}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vsurf_heatmap.png}
    \caption{"Image" Representation of Volatility Surface (01/08/2023). The upper panel shows the heatmap of the volatility surface for Apple Inc. (AAPL), while the lower panel shows the volatility surface for the S$\&$P 500 index (SPX) on the same date. The x-axis represents moneyness (option delta), and the y-axis represents days to expiration, with color intensity indicating implied volatility levels.}
    \label{fig:vsurf_heatmap}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vit_figure.png}
    \caption{Vision Transformer (ViT) Architecture from \citet{dosovitskiyImageWorth16x162020}. The image is split into fixed-size patches, linearly embedded, and then position embeddings are added. The resulting sequence of vectors is fed to a standard Transformer encoder. Similar to BERT, a classification token is prepended to the sequence, and the final hidden state corresponding to this token is used for classification tasks.}
    \label{fig:vit_figure}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/channel_vit_figure.png}
    \caption{Channel Vision Transformer (ChannelViT) Architecture from \citet{baoChannelVisionTransformers2024}. The input image comprises multiple channels potentially carrying semantically distinct and independent information. ChannelViT constructs patch tokens for each individual channel, utilizing a learnable channel embedding \textbf{chn} to encode channel-specific information. The linear embedding \textbf{W} and positional embeddings \textbf{pos} are shared across all channels. The resulting sequence of vectors from all channels is concatenated and fed into a standard Transformer encoder. Similar to BERT, a classification token is prepended to the sequence, and the final hidden state corresponding to this token is used for classification tasks.}
    \label{fig:channel_vit_figure}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/port_binary_full.png}
    \caption{Portfolio Performance from Different Models.}
    \label{fig:port_binary_full}
\end{figure}

% \clearpage
% \begin{figure}[htbp]
%     \vfill
%     \centering
%     \includegraphics[width=1\textwidth]{Figures/cumlogret_binary_full.png}
%     \caption{Cumulative Log Return, All Stocks. This figure shows the cumulative log return of equal-weight portfolios formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ from January 2004 to August 2023. The sample includes all stocks with available option-implied volatility surface data. The "Low" series represents the decile portfolio of stocks with the lowest predicted "up" probabilities, while the "High" series represents the decile portfolio with the highest predicted "up" probabilities. The "High - Low" series represents a long position in the "High" portfolio and a short position in the "Low" portfolio.}
%     \label{fig:cumlogret_binary_full}
% \end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/cumret_binary_sp.png}
    \caption{Cumulative Returns, S\&P 500 Stocks. This figure shows the cumulative log return of equal-weight decile portfolios formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ from January 2004 to August 2023. The sample includes only stocks that are part of the S\&P 500 index. The "Low" series represents the 1/3 stocks with the lowest predicted "up" probabilities, while the "High" series represents the 2/3 stocks with the highest predicted "up" probabilities. The "SPY" series represents the cumulative log return of the S\&P 500 index ETF (SPY) over the same period.}
    \label{fig:cumlogret_binary_sp}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/kmeans_2D_100.png}
    \caption{Classification Visualization (K-Means Clustering)}
    \label{fig:kmeans_2D_100}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/port_kmeans.png}
    \caption{Portfolio Performance from K-Means Clustering (100 Clusters)}
    \label{fig:port_kmeans_mu_s}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/cumret_kmeans_sp.png}
    \caption{Cumulative Returns, S\&P 500 Stocks (K-Means Clustering, 100 Clusters)}
    \label{fig:cumret_kmeans_sp}
\end{figure}



\clearpage
\appendix
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\setcounter{table}{0}
\setcounter{figure}{0}
\section{Vision Transformer Model Structure} \label{sec:appendixa}
%\addcontentsline{toc}{section}{Appendix A}

\section{Option-Based and Other Characteristics} \label{sec:appendixb}
%\addcontentsline{toc}{section}{Appendix B}
This section provides additional details on the option-based characteristics used in the empirical tests. We select a set of most significant characteristics from \citet{neuhierlOptionCharacteristicsCrosssectional2022}. Most of these variables are calculated from the standardized option-implied volatility surface data (vsurfdYYYY), while the option volume are from the trading volume data (opvoldYYYY). Monthly sample period is from January 1996 to August 2023, same as the date range of OptionMetrics data.
\begin{itemize}
    \item $\textbf{CIV}$ \& $\textbf{PIV}$: Near At-The-Money (ATM) call and put implied volatility with maturity of 30 days and absolute delta of 0.5, following \citet{anJointCrossSection2014a}
    \item $\Delta \textbf{CIV}$ \& $\Delta \textbf{PIV}$: Monthly change in the near ATM call and put implied volatility, also from \citet{anJointCrossSection2014a}
    \item \textbf{SKEW}: Difference between average put and call IV, using options with 30 days to expiration and average across call with delta between 0.2 to 0.4, and put with delta between -0.2 to -0.4, following \citet{neuhierlOptionCharacteristicsCrosssectional2022}.
    \item \textbf{log(O/S)}: Total monthly option volume over all call and put options, divided by monthly stock trading volume, following \citet{johnsonOptionStockVolume2012a}.
    \item $\textbf{IVS}_{ATM}$: Difference between the near ATM put (delta = -0.5 and maturity = 30 days) and call (delta = 0.5 and maturity = 30 days) implied volatility, using the last daily observation of each month, following \citet{yanJumpRiskStock2011}.
    \item $\textbf{IVS}_{OTM}$: Difference between the Out-The-Money (OTM) put implied volatility with moneyness closest to but above 1, and the OTM call implied volatility with moneyness closest to but below 1, using options with expiration between 10 and 60 days, following \citet{xingWhatDoesIndividual2010}.
\end{itemize}

Thanks to the work of \citet{CFR-0112}, we are able to directly download most of these option characteristics from their website \footnote{\url{https://www.openassetpricing.com/}}. The methodology that they used closely followed the original papers with only minor modifications. It is worth noting that we use the same name conventions as in \citet{neuhierlOptionCharacteristicsCrosssectional2022}, while the construction of these variables might be slightly different from them.

Besides these option-based characteristics, we also include the following commonly used stock characteristics as control variables in the empirical tests: CAPM beta (beta), logarithm of market capitalization (log(ME)), past 1-month return ($ret_{1, 0}$), past 12-month return excluding the most recent month ($ret_{12, 2}$). These stock characteristics are also downloaded from \citet{CFR-0112}, except for the CAPM beta, which is downloaded from the Beta Suite by WRDS\footnote{\url{https://wrds-www.wharton.upenn.edu/pages/get-data/beta-suite-wrds/}}, calculated using daily returns over a 252-trading-day estimation window and a 126-trading-day minimum requirement.

\section{Additional Results} \label{sec:appendixc}
%\addcontentsline{toc}{section}{Appendix C}
\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{4pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Portfolio Analysis, Binary Classification Model, Non-Micro Stocks}
\label{tab:portfolio_binary_nm}
\begin{threeparttable}
\input{Tables/portfolio_binary_models_nm.tex}
\begin{tablenotes}
    \footnotesize
    \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
\end{tablenotes}
\end{threeparttable}
\end{table}


% \begin{table}[htbp]
% \centering
% \small
% \setlength{\tabcolsep}{4pt}
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Portfolio Analysis, Binary Classification Model, S\&P 500 Stocks}
% \label{tab:portfolio_binary_micro}
% \begin{threeparttable}
% \input{Tables/portfolio_binary_sp.tex}
% \end{threeparttable}
% \end{table}


\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{4pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Time Series Regression, Binary Classification Model, Non-Micro Stocks}
\label{tab:ts_reg_binary_nm}
\begin{threeparttable}
\resizebox{\textwidth}{!}{\input{Tables/ts_reg_binary_models_nm.tex}}
\end{threeparttable}
\end{table}

% \begin{table}[htbp]
% \centering
% \small
% \setlength{\tabcolsep}{4pt}
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Time Series Regression, Binary Classification Model, S\&P 500 Stocks}
% \label{tab:ts_reg_binary_large}
% \begin{threeparttable}
% \resizebox{\textwidth}{!}{\input{Tables/ts_reg_binary_sp.tex}}
% \end{threeparttable}
% \end{table}

\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{6pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Fama-MacBeth Regression, Binary Classification Model, Non-Micro Stocks}
\label{tab:fm_reg_binary_nm}
\begin{threeparttable}
\input{Tables/fm_reg_binary_models_nm.tex}
\end{threeparttable}
\end{table}




\end{document}