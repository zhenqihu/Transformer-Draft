\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,sectsty,comment,natbib,footmisc,pdflscape,subfigure,array,hyperref,booktabs,hypcap,siunitx,threeparttable,rotating,longtable,booktabs,threeparttablex}


\normalem

\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}

\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}
\renewcommand{\TPTnoteSettings}{%
  \setlength{\leftmargin}{0pt}%     % 列表环境的左边距
  \setlength{\itemindent}{0pt}%    % 列表项第一行的缩进
  \setlength{\labelwidth}{0pt}%     % 标签（如 [a]）的宽度
  \setlength{\labelsep}{0pt}%      % 标签和文本之间的距离
}

\begin{document}

\begin{titlepage}
\title{Recovering Predictability from the Implied Volatility Surface: A Transformer Approach\thanks{abc}}
% \author{Zhenqi Hu\thanks{abc}}
\date{\today}
\maketitle
\begin{abstract}
\noindent Placeholder\\
\vspace{0in}\\
\noindent\textbf{Keywords:} key1, key2, key3\\
\vspace{0in}\\
\noindent\textbf{JEL Codes:} key1, key2, key3\\

\bigskip
\end{abstract}
\setcounter{page}{0}
\thispagestyle{empty}
\end{titlepage}
\pagebreak \newpage




\doublespacing


\section{Introduction} \label{sec:introduction}
The information contained in options market has been widely studied since the birth of options 
market. There exists a series of well-developed theories that uncover the risk-neutral, as well as physical or real probabilities of the underlying asset returns from their option prices \citep{breedenPricesStateContingentClaims1978,coxSurveyNewResults1976,coxValuationOptionsAlternative1976,rossRecoveryTheorem2015}. However, the practical implementation of extracting the information from option prices is often challenging, due to the discrete nature of option strike prices and maturities, limited liquidity of option market, as well as the model misspecification issues.

Recent years have witnessed the rapid development of machine learning and deep learning techniques, and their applications in the research of finance area \citep{guEmpiricalAssetPricing2020,bianchiBondRiskPremiums2021,jiangReImaginingPriceTrends2023}. These advanced methods have shown great potential in extracting complex, non-linear patterns from high-dimensional, and unstructured data, which are often difficult to capture using traditional econometric models. Motivated by these advancements, we propose to leverage the well known deep learning architecture, namely the Transformer model, to recover the content embedded in the options market. 

Since the work of \citet{vaswaniAttentionAllYou2017}, the Transformer model has revolutionized the field of natural language processing (NLP) and has been widely adopted in various applications, such as machine translation, text summarization, and sentiment analysis. The core component of the Transformer architecture is the self-attention mechanism, which allows the model to weigh the importance of different words in a sentence when making predictions. This mechanism enables the model to capture long-range dependencies and contextual information effectively, leading to significant improvements in performance compared to previous models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs). Building on the success of the Transformer, large language models (LLMs), such as GPT series \citep{brownLanguageModelsAre2020} and BERT \citep{devlinBERTPretrainingDeep2019}, have further pushed the boundaries of what is possible with deep learning in NLP, achieving state-of-the-art results on a wide range of tasks.

We use the option-implied volatility surface (IVS) as the main input feature to our deep learning models. The IVS is a three-dimensional representation of implied volatilities across different strike prices and maturities, and empirical literatures have shown that transformations of the IVS have significant predictive power for future stock returns \citep{baliVolatilitySpreadsExpected2009,xingWhatDoesIndividual2010,yanJumpRiskStock2011}. Moreover, \citet{martinWhatExpectedReturn2017,martinWhatExpectedReturn2019} proposed a options-based bounds on expected stock returns.


\section{Related Work}


\section{Data} \label{sec:data}
\subsection{Option-Implied Volatility Surface (IVS)} \label{sec:ivs}
We obtain the equity and index option data from the IvyDB OptionMetrics database, which provides the files (vsurfdYYYY) that contain the interpolated Black-Scholes option-implied volatilities, starting from January 1996. For each security on each day, a volatility surface with standard maturities of $\tau$ days to expiration and moneyness levels measured by option $\delta$ is provided. \footnote{OptionMetrics use a methodology based on a kernel smoothing algorithm to interpolate the volatility surface. The maturities are 10, 30, 60, 91, 122, 152, 182, 365, 547, 730 days to expiration, and the option delta levels are from 0.1 to 0.9 with a step of 0.05, positive for call options and negative for put options.}

We select out-of-the-money (OTM) and near at-the-money (ATM) put options with delta levels in [-0.5, -0.1], as well as OTM and near ATM call options with delta levels in [0.1, 0.5], since the deep-in-the-money call options are often illiquid, following \citet{martinWhatExpectedReturn2017}, among others. The options are rearranged by their moneyness (implied strike), so the delta levels start from -0.1 to -0.5, then from 0.5 to 0.1 \footnote{The implied strike order between put option with delta -0.5 and call option with delta 0.5 is uncertain, but their spread is proved to have predictive power for future returns \citep{yanJumpRiskStock2011}, so we keep both of them.}. We also drop the options with maturities equal to 10 days, since the large fraction of missing values. The final volatility surface data contains 10 maturities and 18 delta levels, and a example of the volatility surface is shown in Figure \ref{fig:vsurf_3d_plot}. The implied volatility surface of each security $i$ at time $t$ can be represented as a collection of volatility values at different maturities and delta levels: 
\begin{align}
IV_{i, t} &= \{IV_{i,t}(\tau, \delta)\}_{\tau \in T, \delta \in \Delta} \\
T &= \{30, 60, 91, 122, 152, 182, 365, 547, 730\} \nonumber \\
\Delta &= \{-0.5, -0.45, ..., -0.1, 0.1, 0.15, ..., 0.5\} \nonumber
\end{align}
Where $IV_{i,t}(\tau, \delta)$ represents the implied volatility level at maturity $\tau$ and delta level $\delta$ for security $i$ at time $t$, which serves as the main input feature in our Transformer models.

We obtain the daily return data from CRSP for all firms listed on NYSE, AMEX, and NASDAQ, as well as the S$\&$P 500 index. For each security $i$ at time $t$, we calculate the cumulative return on security $i$ from day $t$ to day $t+H$ as:
\begin{align}
    r_{i,t}^H = \prod_{j=0}^{H-1} (1 + r_{i,t+j}) - 1
\end{align}

We link the volatility surface data from OptionMetrics with the return data from CRSP using a linking table provided by WRDS. The final dataset spans from January 1996 to August 2023, and Figure \ref{fig:num_stocks_vsurf} shows the coverage of the stocks with available volatility surface and return data over time. The number of stocks increases significantly over time, from below 1000 to over 5000 in recent years.

\subsection{Option-Based and Other Characteristics} \label{sec:char}
Motivated by the extensive literature from cross-section studies of stock returns, we also collect a set of option-based predictors that have been shown to have predictive power for future stock returns. \citet{neuhierlOptionCharacteristicsCrosssectional2022} and \citet{muravyevWhyDoesOptions2025} summarized a comprehensive list of such option characteristics and compared their performance. We follow their results and select the strongest ones. Other common stock characteristics are also collected. A detailed description of these characteristics is provided in Appendix \ref{sec:appendixb}.


\section{The Transformer Model} \label{sec:model}
In this section, we briefly introduce the vanilla Transformer model and Vision Transformer (ViT) model architectures and our experimental designs.

\subsection{Brief Introduction of the Transformer Encoder and Vision Transformer} \label{sec:transformer}
First introduced by \citet{vaswaniAttentionAllYou2017}, "Attention Is All You Need," the Transformer model has become a foundational architecture in deep learning, particularly for natural language processing (NLP). Unlike its predecessors, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, the Transformer does not rely on sequential data processing. Instead, it processes the entire input sequence at once, using a sophisticated mechanism known as self-attention to weigh the importance of different words in the sequence.

The Transformer architecture is depicted in Figure \ref{fig:transformer_figure}. The core of the model is its encoder-decoder structure. The encoder's role is to map an input sequence of symbol representations $(x_1, ..., x_n)$ to a sequence of continuous representations $\mathbf{z}=(z_1,...,z_n)$. The decoder then takes $\mathbf{z}$ and generates an output sequence $(y_1,...,y_m)$, one symbol at a time. In our study, we want to leverage the Transformer architecture for predicting stock returns based on the option-implied volatility surface, instead of the time series self-prediction tasks. Therefore, we focus on the Transformer encoder part of the architecture, that is, the left half of Figure \ref{fig:transformer_figure}, which is responsible for encoding the input sequence into a dense vector representation. The so-called "Encoder-Only" architecture, has been widely used in various applications, such as BERT \citep{devlinBERTPretrainingDeep2019} for language understanding and other domains beyond NLP.

Building on the success of the Transformer in NLP, the Vision Transformer (ViT) was proposed by \citet{dosovitskiyImageWorth16x162020} to apply the same architecture to computer vision tasks, offering a compelling alternative to the widely used Convolutional Neural Networks (CNNs). The fundamental idea behind ViT is to treat an image as a sequence of patches, analogous to how a sentence is treated as a sequence of words. By converting images into a sequential format, ViT demonstrates that the reliance on convolutions is not a necessity for vision tasks and that a general-purpose attention-based architecture can achieve state-of-the-art (SOTA) performance, especially when pre-trained on large datasets.

In the computer vision (CV) field, a image is typically represented as a three-dimensional matrix with $(C, H, W)$ dimensions, where $C$ is the number of channels (e.g., $C=3$ for RGB images, and $C=1$ for grayscale images), $H$ is the height (number of pixels in vertical direction), and $W$ is the width (number of pixels in horizontal direction). Each pixel in the image has a value ranging from 0 to 255, representing the intensity of the color channel(s) at that pixel. In the ViT model, the input image is first divided into fixed-size patches (e.g., $16 \times 16$ pixels), and each patch is then flattened into a vector. These patch vectors are linearly embedded into a higher-dimensional space, and positional encodings are added to retain spatial information. The resulting sequence of embedded patches is then fed into a standard Transformer encoder, similar to the original Transformer architecture used in NLP. The ViT model can be visualized as shown in Figure \ref{fig:vit_figure}.

We consider two different model structures, mainly differing in the way of representing the implied volatility surface data as input features, that is, the "embedding" stage of the Transformer model. The next section describes the two different embedding methods in detail, and the details of the model architecture are provided in Appendix \ref{sec:appendixa}.

\subsection{Embedding of the Implied Volatility Surface} \label{sec:embedding}
\subsubsection*{Time Series Representation}
The first method treats the volatility surface as a time series of flattened vectors over the past month. At each time $t$, the volatility surface of security $i$ can be represented as a two-dimensional matrix with dimensions $(N_{\tau}, N_{\delta})$, where $N_{\tau}$ is the number of maturities and $N_{\delta}$ is the number of moneyness levels. We then flatten the matrix into a vector of size $N_{\tau} \times N_{\delta}$. To capture the time series dynamics of the volatility surface, we collect the volatility surfaces over the past $B$ days (e.g., $B=21$ trading days for one month), and stack them together to form a sequence of vectors $\left(x_1, x_2, ..., x_B\right)$, where each vector $x_j \in \mathbb{R}^{N_{\tau} \times N_{\delta}}$ represents a flattened volatility surface at time step $j$ in the lookback window.

We use a linear embedding layer to project the input vectors into the model dimension $d_{model}$, followed by adding a positional encoding to retain the temporal information\footnote{We use the sinusoid function as in \citet{vaswaniAttentionAllYou2017}, see Appendix \ref{sec:appendixa} for details}. The embedded sequence is then fed into the Transformer encoder, and we select the last temporal output in the last layer as the dense vector representation of the volatility surface information\footnote{Alternatively, we can also use the mean pooling of all temporal outputs in the last layer $\frac{1}{21} \sum_{j=0}^{20} \mathbf{z}_L^{j}$ as the vector representation. Since the sequence here is a time series, the last temporal output is more intuitive and might contain more recent information.}. The model can be simply expressed as:
\begin{align}
    \mathbf{v}_{i, t} = \text{Transformer}([IV_{i, t-B+1}; IV_{i, t-B+2}; ...; IV_{i, t}] | \theta)
\end{align}
Where $IV_{i, t}$ represents the implied volatility surface of security $i$ at time $t$, and $\mathbf{v}_{i, t} \in \mathbb{R}^{d_{model}}$ is the output dense vector representation of the information contained in the volatility surfaces, and $\theta$ is the set of parameters needed to be learned through training. $\text{Transformer}(\cdot | \theta)$ represents the non-linear mapping from the input sequence to the output vector through the linear embedding, positional encoding and the Transformer encoder, while not including the final classification head. This approach treats each volatility surface as a token and construct the sequence based on the time series order. The benefit of this embedding methodology is its ability to capture the temporal dynamics of the volatility surface over a certain period, while the weakness is that it ignores the spatial structure of the volatility surface itself. We refer to this model as the \textbf{TF} (Temporal Transformer) model in the following sections.

Besides the implied volatility surface of individual stocks, we also consider to incorporate the implied volatility surface of the S$\&$P 500 index options as an additional input. The index options contain essential information of market-wide risk and risk premia, in time series as well as in cross-section, providing incremental predictive power for the stock returns \citep{andersenRiskPremiaEmbedded2015,angCrossSectionVolatilityExpected2006}. We simply concatenate the flattened index volatility surface with the flattened stock volatility surface along the feature dimension, resulting in an input vector of size $(B, 2 \times N_{\tau} \times N_{\delta})$, and the model can be expressed as:
\begin{align}
    \mathbf{v}_{i, t} = \text{Transformer}([(IV_{i, t-B+1}, IV_{spx, t-B+1}); ...; (IV_{i, t}, IV_{spx, t})] | \theta)
\end{align}
Where $IV_{spx, t}$ represents the implied volatility surface of the S$\&$P 500 index at time $t$.

\subsubsection*{Image Representation}
An option-implied volatility surface can be represented as a three-dimensional plot that displays the implied volatility of a security options across different strike prices and expirations (Figure \ref{fig:vsurf_3d_plot}). Therefore, the volatility surface is analogous to a single-channel grayscale image: The height $H$ of the matrix corresponds to the number of maturities $N_{\tau}$, and the width $W$ corresponds to the number of moneyness levels $N_{\delta}$ (Figure \ref{fig:vsurf_heatmap}). 

We implement a standard Vision Transformer (ViT) model to extract the information from the volatility surface. Each volatility surface $IV_{i,t}$ is reshape as a three-dimensional matrix with dimensions $(1, N_{\tau}, N_{\delta})$, where the first dimension represents the single channel of the grayscale image. The ViT model splits the input image into fixed-size patches. In this study, we simply set the patch size to be $(1, 1)$, meaning that each patch contains a single volatility value in the surface. Each patch (volatility value) is linearly embedded into a higher-dimensional space ($d_{model}$), and learnable positional encoding is added to retain the spatial information, as well as a learnable classification token (CLS token) is prepended to the sequence of embedded patches (see more details in Appendix \ref{sec:appendixa}). The resulting sequence of embedded patches is then fed into a standard Transformer encoder. Finally, the output corresponding to the CLS token in the last layer is selected as the dense vector representation of the volatility surface information. The model can be simply expressed as:
\begin{align}
    \mathbf{v}_{i, t} = \mathbf{ViT}(IV_{i, t} | \theta)
\end{align}
Where the $ViT(\cdot | \theta)$ denote the non-linear mapping from the input image (volatility surface) to a dense vector representation of the image, except for the final classification head.
We refer to this model as the \textbf{ViT} (Vision Transformer) model in the following sections.

We also consider to incorporate the index volatility surface as the additional input, and it's natural to treat the index volatility surface as another channel of the input image. However, unlike standard RGB images, where the three channels (Red, Green, Blue) contain correlated and complementary information about the same object, the two implied volatility surfaces in our case contain semantically distinct and independent information. This poses a challenge for the standard ViT model, which is designed to process images with correlated channels. Inspired by \cite{baoChannelVisionTransformers2024}, we use the so-called ChannelViT model for the embedding of the multiple volatility surfaces. Specifically, the ChannelViT model, shown in Figure \ref{fig:channel_vit_figure}, processes each input channel (volatility surface) independently in the embedding stage. Each channel (volatility surface) is split into patches, linearly embedded, and employs a set of learnable channel embeddings to encode the channel-specific information besides the positional embeddings. The resulting sequence of vectors from all channels is then concatenated and fed into the Transformer encoder. Since the two volatility surfaces have the exactly the same structure (same maturities and moneyness levels), they share a common positional encoding matrix. The model can be expressed as:
\begin{align}
    \mathbf{v}_{i, t} = \mathbf{ViT}([IV_{i, t}, IV_{spx, t}] | \theta)
\end{align}
Where $[IV_{i, t}, IV_{spx, t}]$ represents the two-channel volatility surface image, with the first channel being the stock volatility surface and the second channel being the index volatility surface at the same time $t$.

\subsubsection*{Temporal-Spatial Hybrid Representation}
A natural extension of the above two embedding methods is to combine both the temporal dynamics and spatial structure of the volatility surface, which regard the volatility surface data as a sequence of images over time, similar to a video data. For example, this can be achieved by stacking the volatility surfaces over the past $B$ days as multiple channels of a single input image, and implementing a ChannelViT model to extract the information. However, this approach would lead to a very long sequence of inputs, resulting in high computational costs and memory requirements.

Alternatively, we can utilize more advanced architectures that combine the strengths of both temporal and spatial modeling, such as TimeSformer \citep{bertasiusSpaceTimeAttentionAll2021} and Video Vision Transformer (ViViT) \citep{arnabViViTVideoVision2021}, which are specifically designed for video data. These models employ specialized attention mechanisms to effectively capture both temporal and spatial dependencies in the data. However, these higher-complexity models require significantly more computational resources and larger datasets for training, which may not be feasible in our current setting. Therefore, we leave the exploration of these hybrid models for future research.


\subsection{Discretization of Returns} \label{sec:classification}

Utilizing the dense vector representation $\mathbf{v}_{i, t}$ obtained from the ViT model, a classification head is attached to perform classification tasks. In our study, such a classification head is a single linear layer followed by a softmax function, as shown in Figure \ref{fig:transformer_figure} and \ref{fig:vit_figure} \footnote{In the original ViT paper, \citet{dosovitskiyImageWorth16x162020} used a multi-layer perceptron (MLP) with one hidden layer at pre-training time and used a single linear layer at fine-tuning time. A recent update, \citet{beyerBetterPlainViT2022} from some of the same authors of the original paper suggests that a simple linear layer at the end is not significantly worse than an MLP. We use a single linear layer for simplicity reason.}, which maps the vector representation $\mathbf{v}_{i, t}$ to a probability distribution over the classes:
\begin{align}
\mathbf{p}_{i,t} &= \text{softmax}(W_c \cdot \mathbf{v}_{i, t} + b_c) \\
\text{softmax}(\mathbf{x})_j &= \frac{e^{x_j}}{\sum_{k=1}^{K} e^{x_k}}, \quad j = 1, ..., K
\end{align}
where $W_c \in \mathbb{R}^{K \times d_{model}}$ and $b_c \in \mathbb{R}^{K}$ are the weights and bias of the linear layer in the classification head, and $K$ is the number of classes. The output $\mathbf{p}_{i,t} \in \mathbb{R}^{K}$ is a probability vector, where each element $\mathbf{p}_{i,t}(k)$ represents the predicted probability of stock $i$'s return falling into class $k$ at time $t$.

The simplest classification is the binary classification, where the number of classes $K=2$. For example, we can classify the stock return into "up" and "down" classes based on whether the future return is positive or negative, as in \citet{jiangReImaginingPriceTrends2023}. Alternatively, the stock return can be classified into "safe" and "crash" classes based on whether the future return is above a certain negative value (e.g., -10\%). In general, we denote $y_{i, t}$ as the binary variable indicating whether stock $i$'s return falls into the two classes defined by a specific threshold $q$ at time $t$:
\begin{align}
    y_{i, t} &= \mathbf{I}(r_{i,t}^H > q) =
    \begin{cases}
    1, & \text{if } r_{i,t}^H > q \\
    0, & \text{if } r_{i,t}^H \leq q
    \end{cases} \\
    \hat{y}_{i,t} &= \mathbf{p}_{i,t}(1)
\end{align}
where $r_{i,t}^H$ is the cumulative return of stock $i$ from day $t$ to day $t+H$, and the output $\hat{y}_{i,t} = \mathbf{p}_{i,t}(1)$ represents the predicted probability of stock $i$'s return being in class 1 at time $t$.  The threshold $q$ can be set to 0 for the "up/down" classification. \footnote{In the special case of binary classification ($K=2$), the softmax function reduces to the logistic (sigmoid) function.}

For multi-class classification ($K > 2$), the stock returns can be discretized into multiple classes based on quantiles or specific thresholds. Assume $\{q_0, q_1, ..., q_K\}$ are the thresholds that define the $K$ classes, where $q_0 = -\infty$ and $q_K = +\infty$. In general, we denote $y_{i, t}$ as the categorical variable indicating which class stock $i$'s return falls into at time $t$:
\begin{align}
    y_{i, t} &= k, \quad \text{if } r_{i,t}^H \in (q_{k-1}, q_k], \quad k = 1, 2, ..., K \\
    \hat{y}_{i,t}^k &= \mathbf{p}_{i,t}(k)
\end{align}

\subsection{Training Process} \label{sec:training}
We use standard cross-entropy loss function for the classification task. For binary classification, where $y \in \{0, 1\}$, the loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \left[y \log(\hat{y}) + (1-y) \log(1-\hat{y})\right]
\end{align}

For multi-class classification, where $y \in \{1, 2, ..., K\}$, the loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \sum_{k=1}^{K} \mathbf{I}(y = k) \log(\hat{y}^k)
\end{align}
where $\hat{y}^k$ is the predicted probability of class $k$.

In the case of imbalanced classes, we can use a weighted cross-entropy loss function to give more importance to the minority classes. The weighted loss function can be expressed as:
\begin{align}
    \mathcal{L}(y, \hat{y}) &= - \sum_{k=1}^{K} w_k \cdot \mathbf{I}(y = k) \log(\hat{y}^k) \\
    w_k &= \frac{N}{K \cdot N_k}
\end{align}
where $w_k$ is the weight for class $k$, $N$ is the total number of samples, and $N_k$ is the number of samples in class $k$. This weighting scheme helps to balance the influence of each class during training, especially when some classes are underrepresented.

We adopt similar regularization techniques as in \citet{guEmpiricalAssetPricing2020}, to prevent overfitting and improve the comuputational efficiency. We use a Adaptive Moment Estimation With Weight Decay (AdamW) optimizer \citep{loshchilovDecoupledWeightDecay2019}, which is standard in the transformer training and a refined version of the Adam optimizer \citep{kingmaAdamMethodStochastic2017}. AdamW decouples the weight decay (L2 regularization) from the gradient update, which has been shown to lead to better generalization performance. In this study, we set the learning rate to $1\times 10^{-5}$, the weight decay to $1\times 10^{-2}$ and the batch size to 512. We use a dropout rate of $0.2$ to prevent overfitting. Dropout is a regularization technique that randomly sets a fraction of the input units to zero during training, which helps prevent overfitting by reducing the model's reliance on specific features. 

We apply multiple methods for parameter initialization: for weights in the patch embedding layers and classfication head, we use the Xavier initialization \citep{glorotUnderstandingDifficultyTraining2010}, which is the best practice for deep neural networks such as CNNs; for parameters in the CLS token and positional embeddings, as well as the weights in the Transformer encoder, we use a truncated normal distribution with a standard deviation of $0.02$, following the BERT model \citet{devlinBERTPretrainingDeep2019}; for layer normalization parameters, we initialize the weights to 1; the biases in all layers are initialized to 0. We use a standard "warm-up" and "cosine decay" learning rate scheduler, which gradually increases the learning rate from zero to the initial value over a specified number of warm-up steps, and then decays it using a cosine function. This approach helps stabilize training in the early stages and allows for better convergence. Early stopping is also employed, where the training process is halted if the validation loss does not improve for a two consecutive epochs, to prevent overfitting and save computational resources.

We train each model using annually updated rolling window, given the time-varying universe of stocks in \ref{fig:num_stocks_vsurf}. Specifically, we use a 8-year in-sample period, with 6 years for training and 2 years for validation, to predict the out-of-sample returns for the subsequent year. The first training period starts from January 1996 to December 2003, and the trained model is then used to predict out-of-sample returns for the subsequent year 2004. The model is then updated with the data from 2004, and used to predict out-of-sample returns for 2005. This process continues until August 2023, the last month of our dataset. Overall, the out-of-sample prediction period is from January 2004 to August 2023, which contains around 20 years of results. The daily dataset provides a large number of training samples, which is crucial for training such a large deep learning model, while we only collect the out-of-sample predictions at the end of each month for empirical analysis. Since the stochastic nature of the Vision Transformer model, we train each specific model for five times and calculate the average predictions, following \citet{guEmpiricalAssetPricing2020}.

\section{Empirical Results} \label{sec:binary_results}
\subsection{Binary Classification: Up and Down} \label{sec:binary_classification}
We begin with the simplest binary classification problem ($K = 2$). Following \citet{jiangReImaginingPriceTrends2023}, the stock returns are simply classified into "up" and "down" classes based on whether the future return is positive or negative. Besides the simplicity and interpretability, one remarkable benefit of such binary classification is that the two classes are naturally more balanced in our dataset, which is to say, there are approximately $50\%$ "up" labels and $50\%$ "down" labels. This is crucial for the training of such deep learning or machine learning models, since imbalanced classes can lead to suboptimal performance, as the model may become biased towards the majority class \citep{heLearningImbalancedData2009a}.

We focus on the prediction of 1-month ahead stock returns ($H=21$ trading days), which is common in the literature of cross-section of stock returns studies. We consider four different model specifications: (1) Temporal Transformer (TF) model with only stock volatility surface as input, the lookback window is $L=21$ days, covering the last month. Since the volatility surface data contains 10 maturities ($N_{\tau}=10$) and 18 moneyness levels ($N_{\delta}=18$), we call this model \textbf{TF180}; (2) Temporal Transformer (TF) model with both stock and index volatility surfaces as input, the lookback window is also $L=21$ days, resulting in an input size of $2 \times 10 \times 18 = 360$ features per day, we call this model \textbf{TF360}; (3) Vision Transformer (ViT) model with only stock volatility surface as input, we call this model \textbf{ViT180}; (4) Channel Vision Transformer (Channel ViT) model with both stock and index volatility surfaces as input, we call this model \textbf{ViT360}.

Table \ref{tab:portfolio_binary_full} reports the portfolio performance of equal-weight and value-weight decile portfolios, including a long-short spread portfolio "10-1", formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ in each month's end, with a holding period of one month. All the four model specifications generate significant positive returns for the long-short portfolio. Moreover, Figure \ref{fig:port_binary_full} plot the decile portfolio returns, as well as two of the most prominent option-base predictors in the literature: the implied volatility spread between ATM call and put options (\textbf{IVSpread}) defined in \citet{yanJumpRiskStock2011}, and the implied volatility skew betwen OTM put and ATM call options (\textbf{IVSkew}) defined in \citet{xingWhatDoesIndividual2010}. More details about these two predictors are provided in Appendix \ref{sec:appendixb}. 

As mentioned in \citet{muravyevWhyDoesOptions2025}, the spreads of the two predictors stem from the decile one's (short-leg) underperformance, while the returns in higher deciles are relatively flat. This is consistent with the intuition that options market contains more information about the extreme negative returns (left tail) since investors are more likely to join the options market for hedging purposes. The decile portfolio returns from our four Transformer-based models present a similar pattern, where the long legs are relatively flat and close to the two spread predictors but the short legs generate lower returns. This indicates that our models are able to capture more information about the downside risk, excelling the performance of the two spread predictors.

It is difficult to interpret the Transformer-based models directly, due to the complex nonlinear structure. We attempt to interpret the model predictions through relating them to the known option-based and fundamental characteristics. Table \ref{tab:corr_binary_models} reports the univariate correlations between the models' predictions and a set of these characteristics. Following the standard practice in the cross-section studies of stock returns, the correlation matrix is calculated on each month, and then averaged over the test sample period. The results of four specifications show a similar pattern: the model predictions are positively correlated with the firm size log(ME) and negatively correlated with CAPM beta ($\beta$), as well as the implied volatility level (ATM call and put IV) and idiosyncratic volatility (Ivol). Table \ref{tab:port_char_binary} further reports the portfolio characteristics of decile portfolios and presented similar patterns.

In addition to the standard portfolio analysis, we also examine the time series regression of the long-short value-weighted portfolio returns on common risk factors. Table \ref{tab:ts_reg_binary_models} reports the results of regressing the long-short portfolio returns on the Fama-French 5 factors \citep{famaFivefactorAssetPricing2015} augmented with the momentum factor \citep{carhartPersistenceMutualFund1997}. All the four specifications generate significant positive alphas, ranging from 1.1\% to 1.5\% on a monthly basis, economically larger than the IVSpread and IVSkew predictors. The factor exposures are also similar among the four models, with significant negative loadings on the market factor (MKT) and size factor (SMB), and significant positive loadings on the profitability factor (RMW).

Table \ref{tab:ts_reg_binary_models_alt} further reports the time series regression results when using the option-based factors. The ViT360 model generates a significant alpha of 1.8\% on monthly basis, while the other three models also generate positive alphas, though not statistically significant. The results of alphas, as well as the regression $R^2$, suggest that the ViT360 model is able to capture more information from the volatility surfaces beyond the known option-based predictors, while the predictive power of the other three models can be mostly explained by the known option characteristics.

The Fama-MacBeth regression results in Table \ref{tab:fm_reg_binary_full} further confirm the incremental predictive power of our models. The ViT360 model generates a significant positive coefficient, even after controlling for a comprehensive set of option-based and fundamental characteristics. The other three models also generate positive coefficients, though not statistically significant after controlling for those characteristics.

Since the profit of the long-short portfolio mainly drives from the short leg (decile 1), which has the smallest average market size (Table \ref{tab:port_char_binary}), we further conduct the same analysis on the sample excluding the smallest 20\% stocks according to the NYSE size breakpoints. The results are reported in Appendix \ref{sec:appendixc}, and the conclusions remain unchanged.

Following \citet{jiangReImaginingPriceTrends2023}, we conduct a logistic regression of the realized future return indicator on the out-of-sample forecasted probabilities, while controlling for the other option-based and fundamental characteristics. We focus on the best-performing ViT360 model, and Table \ref{tab:logistic_reg_binary_full} reports the results. The dependent variable is an indicator for a positive 1-month future return, and the positive and significant coefficient of our predicted probability indicates a strong predictive power, even after controlling for the previously studied characteristics. In Table \ref{tab:logistic_reg_crash_full}, we further conduct a series of logistic regressions using the crash indicator as the dependent variable, defined as whether the future return is below certain negative thresholds (-10\%, -20\%, -30\%). Consistent with the strong predictive power for extreme negative returns discussed above, the coefficients of our predicted probabilities are significantly negative and have larger economic magnitudes, compared the results when using the positive return indicator as the dependent variable.


\subsection{Multi-Class Classification: Joint Distribution of Stock and Market Returns} \label{sec:multi_joint}
In this section, we extend our analysis to multi-class classification problems ($K > 2$). Furthermore, we try to predict the joint distribution of future stock returns, as well as the market return, by simultaneously predicting the classes of both stock and market returns. 
\subsubsection*{Discretization of Joint Returns} \label{sec:joint_classification}



\section{Conclusion} \label{sec:conclusion}



\singlespacing
\setlength\bibsep{0pt}


\clearpage

\onehalfspacing
\bibliographystyle{rfs}
\bibliography{ref}
\clearpage

\section*{Tables} \label{sec:tab}
\addcontentsline{toc}{section}{Tables}


\begin{table}[htbp]
\centering
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)},
    input-open-uncertainty = {(},
    input-close-uncertainty = {)}
}
\setlength{\tabcolsep}{3pt}
\begin{threeparttable}
\caption{Portfolio Analysis, Binary Classification Model}
\label{tab:portfolio_binary_full}
\input{Tables/portfolio_binary_models.tex}
\begin{tablenotes}
    % \footnotesize
    % \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
    \item This table reports the monthly average returns of equal-weight (top panel) and value-weight (bottom panel) decile portfolios formed on the out-of-sample predicted "up" probability $\hat{P}(r_{i,t+1}^{21} > 0)$ from four different model specifications described in Section \ref{sec:binary_classification}. The long-short portfolio ($10 - 1$) is formed by longing the highest decile and shorting the lowest decile. The portfolios are rebalanced monthly and held for one month. The sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}

% \clearpage
% \begin{sidewaystable}[htbp]
% \centering
% \setlength{\tabcolsep}{4pt}
% \small
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Correlation Analysis, Binary Classification Model, All Stocks}
% \input{Tables/corr_binary.tex}
% \label{tab:corr_binary}
% \end{sidewaystable}


\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{12pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\begin{threeparttable}
\caption{Correlation Analysis}
\label{tab:corr_binary_models}
\input{Tables/corr_binary_models.tex}
\begin{tablenotes}
    \item This table reports the average monthly cross-sectional correlations between the out-of-sample predicted "up" probabilities from four different model specifications described in Section \ref{sec:binary_classification} and a set of option-based and fundamental stock characteristics. The correlations are calculated on each month, and then averaged over the test sample period from January 2004 to August 2023. The stock characteristics are described in Appendix \ref{sec:appendixb}.
\end{tablenotes}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{4pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\begin{threeparttable}
\caption{Portfolio Characteristics, Binary Classification Model, All Stocks}
\label{tab:port_char_binary}
\input{Tables/port_char_binary.tex}
\begin{tablenotes}
\item This table report the time series average characteristics of ten equal-weight decile portfolios formed on the out-of-sample predicted "up" probability from model \textbf{ViT360} described in Section \ref{sec:binary_classification}. The sample period is from January 2004 to August 2023. The stock characteristics are described in Appendix \ref{sec:appendixb}.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)}
}
\caption{Time Series Regression, Binary Classification Model, All Stocks}
\label{tab:ts_reg_binary_models}
\begin{threeparttable}
\input{Tables/ts_reg_binary_models.tex}
\begin{tablenotes}
\item This table reports the alpha and factor loadings from the time series regression of the long-short ($10 - 1$) value-weighted portfolio returns on the Fama-French 5 factors \citep{famaFivefactorAssetPricing2015} augmented with the momentum factor \citep{carhartPersistenceMutualFund1997}. The sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{2pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)}
}
\caption{Time Series Regression on Option-Based Factors}
\label{tab:ts_reg_binary_models_alt}
\begin{threeparttable}
\input{Tables/ts_reg_binary_models_alt.tex}
\begin{tablenotes}
\item This table reports the alpha and factor loadings from the time series regression of the long-short ($10 - 1$) value-weighted portfolio returns on a set of option-based factors described in Appendix \ref{sec:appendixb}. The sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{3pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Fama-MacBeth Regression, Binary Classification Model, All Stocks}
\label{tab:fm_reg_binary_full}
\begin{threeparttable}
\input{Tables/fm_reg_binary_models.tex}
\begin{tablenotes}
\item This table reports the \citet{famaRiskReturnEquilibrium1973} regression results of future 1-month stock returns on the out-of-sample predicted "up" probabilities from four different model specifications described in Section \ref{sec:binary_classification}, along with a comprehensive set of option-based and fundamental stock characteristics described in Appendix \ref{sec:appendixb}. The sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Logistic Regression, Future Stock Return}
\label{tab:logistic_reg_binary_full}
\begin{threeparttable}
\input{Tables/logistic_reg_binary_full.tex}
\begin{tablenotes}
\item This table reports the panel logistic regression results of future return indicator on the out-of-sample predicted "up" probabilities from model \textbf{ViT360} described in Section \ref{sec:binary_classification}, along with a comprehensive set of option-based and fundamental stock characteristics described in Appendix \ref{sec:appendixb}. The dependent variable is an indicator for a positive 1-month future return. The test sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}


\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{1pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Logistic Regression, Future Stock Crash}
\label{tab:logistic_reg_crash_full}
\begin{threeparttable}
\input{Tables/logistic_reg_crash_full.tex}
\begin{tablenotes}
\item This table reports the panel logistic regression results of future crash indicators on the out-of-sample predicted "up" probabilities from model \textbf{ViT360} described in Section \ref{sec:binary_classification}, along with a comprehensive set of option-based and fundamental stock characteristics described in Appendix \ref{sec:appendixb}. The dependent variables are indicators for future 1-month returns below certain negative thresholds (-10\%, -20\%, -30\%). The test sample period is from January 2004 to August 2023. The t-statistics are calculated using \citet{neweySimplePositiveSemiDefinite1987} adjusted standard errors with 6 lags, and reported in parentheses. $^{***}$, $^{**}$, and $^{*}$ denote statistical significance at the 1\%, 5\%, and 10\% levels, respectively.
\end{tablenotes}
\end{threeparttable}
\end{table}

\clearpage

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Summary Statistics of K-Means Clustering, 100 Clusters}
\label{tab:kmeans100_summary_stats}
\begin{threeparttable}
\input{Tables/kmeans100_summary_stats.tex}
\begin{tablenotes}
    \item This table reports
\end{tablenotes}
\end{threeparttable}
\end{table}


\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{2pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Portfolio Returns, K-Means Clustering}
\label{tab:portfolio_kmeans_mu_s}
\begin{threeparttable}
\input{Tables/portfolio_kmeans.tex}
\begin{tablenotes}
    \footnotesize
    \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
\end{tablenotes}
\end{threeparttable}
\end{table}

\clearpage
\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{6pt}
\small
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Cross-Sectional Regression, K-Means Clustering, 100 Clusters}
\label{tab:cs_reg_beta}
\begin{threeparttable}
\input{Tables/cs_reg_beta.tex}
\end{threeparttable}
\end{table}

\clearpage



% ------------------------------- Figures ------------------------------- %

\section*{Figures} \label{sec:fig}
\addcontentsline{toc}{section}{Figures}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{Figures/num_stocks_vsurf.png}
    \caption{Number of Stocks with Option-Implied Volatility Surface Data (1996-2023). The figure shows the number of stocks with available option-implied volatility surface data from IvDB OptionMetrics, spanning from January 1996 to August 2023.}
    \label{fig:num_stocks_vsurf}
    
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vsurf_3d_plot.png}
    \caption{Example of Interpolated Option-Implied Volatility Surface (AAPL, 01/08/2023). The plot shows the volatility surface for Apple Inc. (AAPL) on Aug 1st, 2023, with moneyness (option delta) on the x-axis, days to expiration on the y-axis, and implied volatility levels represented by the color gradient.}
    \label{fig:vsurf_3d_plot}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vsurf_heatmap.png}
    \caption{"Image" Representation of Volatility Surface (01/08/2023). The upper panel shows the heatmap of the volatility surface for Apple Inc. (AAPL), while the lower panel shows the volatility surface for the S$\&$P 500 index (SPX) on the same date. The x-axis represents moneyness (option delta), and the y-axis represents days to expiration, with color intensity indicating implied volatility levels.}
    \label{fig:vsurf_heatmap}
\end{figure}


\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=0.5\textwidth]{Figures/transformer_figure.png}
    \caption{Transformer Architecture from \citet{vaswaniAttentionAllYou2017}. The Transformer model consists of an encoder and a decoder, each composed of multiple layers of multi-head self-attention (MSA) and feed-forward neural networks (FFN). The encoder processes the input sequence, while the decoder generates the output sequence, attending to both the encoder's output and its own previous outputs.}
    \label{fig:transformer_figure}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/vit_figure.png}
    \caption{Vision Transformer (ViT) Architecture from \citet{dosovitskiyImageWorth16x162020}. The image is split into fixed-size patches, linearly embedded, and then position embeddings are added. The resulting sequence of vectors is fed to a standard Transformer encoder. Similar to BERT, a classification token is prepended to the sequence, and the final hidden state corresponding to this token is used for classification tasks.}
    \label{fig:vit_figure}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/channel_vit_figure.png}
    \caption{Channel Vision Transformer (ChannelViT) Architecture from \citet{baoChannelVisionTransformers2024}. The input image comprises multiple channels potentially carrying semantically distinct and independent information. ChannelViT constructs patch tokens for each individual channel, utilizing a learnable channel embedding \textbf{chn} to encode channel-specific information. The linear embedding \textbf{W} and positional embeddings \textbf{pos} are shared across all channels. The resulting sequence of vectors from all channels is concatenated and fed into a standard Transformer encoder. Similar to BERT, a classification token is prepended to the sequence, and the final hidden state corresponding to this token is used for classification tasks.}
    \label{fig:channel_vit_figure}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/port_binary_full.png}
    \caption{Portfolio Performance from Different Models.}
    \label{fig:port_binary_full}
\end{figure}

% \clearpage
% \begin{figure}[htbp]
%     \vfill
%     \centering
%     \includegraphics[width=1\textwidth]{Figures/cumlogret_binary_full.png}
%     \caption{Cumulative Log Return, All Stocks. This figure shows the cumulative log return of equal-weight portfolios formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ from January 2004 to August 2023. The sample includes all stocks with available option-implied volatility surface data. The "Low" series represents the decile portfolio of stocks with the lowest predicted "up" probabilities, while the "High" series represents the decile portfolio with the highest predicted "up" probabilities. The "High - Low" series represents a long position in the "High" portfolio and a short position in the "Low" portfolio.}
%     \label{fig:cumlogret_binary_full}
% \end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/cumret_binary_sp.png}
    \caption{Cumulative Returns, S\&P 500 Stocks. This figure shows the cumulative log return of equal-weight decile portfolios formed on out-of-sample predicted "up" probability $\hat{P}(r_{i,t}^{21} > 0)$ from January 2004 to August 2023. The sample includes only stocks that are part of the S\&P 500 index. The "Low" series represents the 1/3 stocks with the lowest predicted "up" probabilities, while the "High" series represents the 2/3 stocks with the highest predicted "up" probabilities. The "SPY" series represents the cumulative log return of the S\&P 500 index ETF (SPY) over the same period.}
    \label{fig:cumlogret_binary_sp}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/kmeans_2D_100.png}
    \caption{Classification Visualization (K-Means Clustering)}
    \label{fig:kmeans_2D_100}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/port_kmeans.png}
    \caption{Portfolio Performance from K-Means Clustering (100 Clusters)}
    \label{fig:port_kmeans_mu_s}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \vfill
    \centering
    \includegraphics[width=1\textwidth]{Figures/cumret_kmeans_sp.png}
    \caption{Cumulative Returns, S\&P 500 Stocks (K-Means Clustering, 100 Clusters)}
    \label{fig:cumret_kmeans_sp}
\end{figure}



\clearpage
\appendix
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\setcounter{table}{0}
\setcounter{figure}{0}
\section{More about Transformer} \label{sec:appendixa}
%\addcontentsline{toc}{section}{Appendix A}

\subsection{Transformer Architecture} \label{sec:transformer_encoder}
In this section, we provide a more detailed explanation of the Transformer architecture (Figure \ref{fig:transformer_figure}) introduced by \citet{vaswaniAttentionAllYou2017}, and how we adapt it for our first model specification, the Temporal Transformer (TF) model.

\begin{itemize}
    \item \textbf{Embeddings}: The input tokens are first converted to vectors of fixed dimension $d_{model}$ through an learned embeddings. Denote the input sequence as $[\mathbf{x}^1, \mathbf{x}^2, ..., \mathbf{x}^N]$, where each token $\mathbf{x}^i \in \mathbb{R}^{d_{input}}$. The embedding layer maps each token to a $d_{model}$-dimensional vector: $[\mathbf{x}^i] \rightarrow [\mathbf{x}^i \mathbf{E}]$, where $\mathbf{E} \in \mathbb{R}^{d_{input} \times d_{model}}$ is the learned embedding matrix. The resulting sequence of embeddings is $[\mathbf{x}^1 \mathbf{E}; \mathbf{x}^2 \mathbf{E}; ...; \mathbf{x}^N \mathbf{E}] \in \mathbb{R}^{N \times d_{model}}$.
    \item \textbf{Positional Encoding}: Since the Transformer architecture contains no recurrence or convolution, it lacks the inherent ability to capture the order of the input sequence. To address this, positional encodings are added to the input embeddings to provide information about the position of each token in the sequence. The positional encoding can be either learned or fixed, and \citet{vaswaniAttentionAllYou2017} proposed a fixed sinusoidal positional encoding defined as:
    \begin{align}
        PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right) \\
        PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
    \end{align}
    where $pos$ is the position index, and $i$ is the dimension index. The positional encodings are added to the input embeddings to form the final input to the encoder:
    \begin{align}
        \mathbf{z}_0 = [\mathbf{x}^1 \mathbf{E}; \mathbf{x}^2 \mathbf{E}; ...; \mathbf{x}^N \mathbf{E}] + \mathbf{E}_{pos}
    \end{align}
    where $\mathbf{E}_{pos} \in \mathbb{R}^{N \times d_{model}}$ is the positional encoding matrix.
    \item \textbf{Encoder}:
    The Transformer encoder consists of $L$ identical layers, each containing two main sub-layers: Multi-Head Self-Attention (MSA) and a Position-wise Feed-Forward Networks (FFN). Each sub-layer is followed by a residual connection and layer normalization. The overall structure of the encoder can be summarized as follows:
        \begin{itemize}
        \item \textbf{Multi-Head Self-Attention (MSA)}: This mechanism allows the model to focus on different parts of the input sequence simultaneously, capturing various aspects of the image. Each attention head computes a weighted sum of the input embeddings, where the weights are determined by the similarity between the query and key vectors. These similarity scores are calculated using Query (Q), Key (K), and Value (V) matrices, which are linear projections of the input embeddings. The attention scores are computed as:
        \begin{align}
            \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
        \end{align}
        where $d_k$ is the dimension of the key vectors, used for scaling. The multi-head attention mechanism allows the model to jointly attend to information from different representation subspaces at different positions.
        For layer $l = 1,...,L$, the MSA block can be expressed as:
        \begin{align}
            \mathbf{z}_l' = \text{LayerNorm}(\text{MSA}(\mathbf{z}_{l-1}) + \mathbf{z}_{l-1})
        \end{align}
        where $\text{LayerNorm}(\cdot)$ denotes layer normalization, and $\mathbf{z}_l' \in \mathbb{R}^{N \times d_{model}}$ is the output of the MSA block at layer $l$.
        \item \textbf{Position-wise Feed-Forward Networks (FFN)}: Following the MSA, a fully connected feed-forward network is applied to each position independently and identically. This FFN typically consists of two linear layers with a non-linear activation function (e.g., ReLU) in between. The FFN can be expressed as:
        \begin{align}
            \text{FFN}(x) &= \text{ReLU}(xW_1 + b_1)W_2 + b_2 \\
            \text{ReLU}(x) &= \max(0, x)
        \end{align}
        where $W_1, W_2$ are weight matrices and $b_1, b_2$ are bias vectors. Besides, dropout is applied after each fully connected layer to prevent overfitting.
        For layer $l = 1,...,L$, the FFN block can be expressed as:
        \begin{align}
            \mathbf{z}_l = \text{LayerNorm}(\text{FFN}(\mathbf{z}_l') + \mathbf{z}_l')
        \end{align}
        where $\mathbf{z}_l \in \mathbb{R}^{N \times d_{model}}$ is the output of the MLP block at layer $l$.
        \end{itemize}
    \item \textbf{Classification Head}: After passing through the $L$ layers of the Transformer encoder, the final output $\mathbf{z}_L \in \mathbb{R}^{N \times d_{model}}$ is obtained. Since our model take the sequence as a time-series data, we select the last time step's output $\mathbf{z}_L^N \in \mathbb{R}^{d_{model}}$ as the encoded vector representation of the input sequence, assuming that it contains the most relevant information for prediction. This vector is then passed through a linear layer followed by a softmax function to produce the class probabilities:
    \begin{align}
        \mathbf{p} = \text{softmax}(\mathbf{z}_L^N W_c + b_c) \\
        \text{softmax}(\mathbf{a})_i = \frac{e^{a_i}}{\sum_{j=1}^{K} e^{a_j}}
    \end{align}
    where $W_c \in \mathbb{R}^{d_{model} \times K}$ and $b_c \in \mathbb{R}^{K}$ are the weights and bias of the linear layer, and $K$ is the number of classes. The output $\mathbf{p} \in \mathbb{R}^{K}$ represents the predicted probabilities for each class.
\end{itemize}

\subsection{Vision Transformer Architecture} \label{sec:vit}
The architecture of the ViT, shown in Figure \ref{fig:vit_figure}, adapts the original Transformer in the following way:
\begin{itemize}
    \item \textbf{Image Patching and Embedding}: The ViT model first reshapes the input image from a 2D grid of pixels into a sequence of flattened 2D patches. A image is typically represented as $\mathbf{x} \in \mathbb{R}^{H\times W \times C}$, where $(H, W)$ is the height and width of the original image, $C$ is the number of channels (e.g., RGB). In the first stage, it is divided into $N$ patches $[\mathbf{x}_p^1, \mathbf{x}_p^2, ..., \mathbf{x}_p^N]$, where each patch $\mathbf{x}_p^i \in \mathbb{R}^{P \times P \times C}$ is a small square region of the image with size $(P, P)$ pixels, and $N = (H \times W) / (P^2)$ is the number of patches. These patches are then flattened and mapped to a latent D-dimensional embedding space through a trainable linear projection: $[\mathbf{x}_p^i] \rightarrow [\mathbf{x}_p^i E]$, where $E \in \mathbb{R}^{(P^2 \cdot C) \times d_{model}}$. This process converts the 2D spatial structure of the image into a 1D sequence of patch embeddings $[\mathbf{x}_p^1 E; \mathbf{x}_p^2 E; ...; \mathbf{x}_p^N E] \in \mathbb{R}^{N \times d_{model}}$, suitable for input into the Transformer encoder.
    \item \textbf{Learnable Class Token and Positional Encoding}: Inspired by the [CLS] token used in BERT (Bidirectional Encoder Representations from Transformers) model \citep{devlinBERTPretrainingDeep2019}, a learnable embedding is prepended to the sequence of patch embeddings. The state of this token at the output of the Transformer encoder serves as the aggregate image representation for classification tasks.
    
    Different from the original Transformer, where the sequence has a natural order (e.g., words in a sentence, or time steps in a time series), the sequence in ViT model represents image patches, which do not have an inherent order. We follow \citet{dosovitskiyImageWorth16x162020} and add learnable positional embeddings to the patch embeddings to retain spatial information about the position of each patch in the original image. This is crucial for the model to understand the spatial relationships between different patches.
    
    The flattened patches, along with the class token and positional embeddings, are served as input to the Transformer encoder:
    \begin{align}
        \mathbf{z}_0 = [\mathbf{x}_{class}; \mathbf{x}_p^1 \mathbf{E}; \mathbf{x}_p^2 \mathbf{E}; ...; \mathbf{x}_p^N \mathbf{E}] + \mathbf{E}_{pos}
    \end{align}
    where $\mathbf{E} \in \mathbb{R}^{(P^2 \cdot C) \times d_{model}}$ is the patch embedding projection matrix, $\mathbf{E}_{pos} \in \mathbb{R}^{(N+1) \times d_{model}}$ is the positional embedding matrix, and $\mathbf{z}_0 \in \mathbb{R}^{(N+1) \times d_{model}}$ is the resulting sequence of embedded patches, with length $N+1$ (including the class token) and embedding dimension $d_{model}$.

    \item \textbf{Encoder}: The Encoder layers used in ViT are similar to the original Transformer model, but with some slight modifications:
    \begin{align}
        \mathbf{z}_l' &= \text{MSA}(\text{LayerNorm}(\mathbf{z}_{l-1})) + \mathbf{z}_{l-1} \\
        \mathbf{z}_l &= \text{FFN}(\text{LayerNorm}(\mathbf{z}_l')) + \mathbf{z}_l'
    \end{align}

    In contrast to the post-normalization used in the original Transformer, the encoder blocks in ViT implement pre-normalization, where layer normalization is applied right before the MSA and FFN blocks, which has been shown to lead to more effective training for deeper networks \citep{xiongLayerNormalizationTransformer2020} without the need for learning rate warm-up. Besides, in the FFN block, GELU (Gaussian Error Linear Unit) activation function \citep{hendrycksGaussianErrorLinear2023} is used instead of ReLU.
    
    \item \textbf{Classification Head}: For image classification, only the output vector
    corresponding to the prepended class token in the final layer ($\mathbf{z}_L^0$) is used, which serves as the aggregate representation of the entire image:
    \begin{align}
        \mathbf{p} = \text{softmax}(\text{LayerNorm}(\mathbf{z}_L^0) W_c + b_c)
    \end{align}
    Additional layer normalization is applied to the class token output before passing it through the linear classification head, because of the pre-normalization structure of the encoder.
\end{itemize}

\section{Option-Based and Other Characteristics} \label{sec:appendixb}
%\addcontentsline{toc}{section}{Appendix B}
This section provides additional details on the option-based characteristics used in the empirical tests. \citet{neuhierlOptionCharacteristicsCrosssectional2022} and \citet{muravyevWhyDoesOptions2025} summarized a comprehensive list of option-based characteristics that have been shown to be useful in explaining the cross-section of stock returns. We select a subset of most significant and widely used option characteristics. Most of these variables are calculated from the standardized option-implied volatility surface data (vsurfdYYYY), while the option volume are from the trading volume data (opvoldYYYY) and the realized volatility are from the historical volatility data (hvoldYYY). Monthly sample period is from January 1996 to August 2023, same as the date range of OptionMetrics data.

Thanks to the work of \citet{CFR-0112} (CZ in the following), we are able to directly download most of these option characteristics from their website \footnote{\url{https://www.openassetpricing.com/}}. The methodology that they used closely followed the original papers with only minor modifications.

\begin{itemize}
    \item $\textbf{CIV}$ \& $\textbf{PIV}$: Near At-The-Money (ATM) call and put implied volatility with maturity of 30 days and absolute delta of 0.5, following \citet{anJointCrossSection2014a}.
    \item $\Delta \textbf{CIV}$ \& $\Delta \textbf{PIV}$: Monthly change in the near ATM call and put implied volatility, also from \citet{anJointCrossSection2014a}.
    \item \textbf{SKEW}: Difference between average put and call IV, using options with 30 days to expiration and average across call with delta between 0.2 to 0.4, and put with delta between -0.2 to -0.4, following \citet{neuhierlOptionCharacteristicsCrosssectional2022}.
    \item \textbf{log(O/S)}: Total monthly option volume over all call and put options, divided by monthly stock trading volume, following \citet{johnsonOptionStockVolume2012a}.
    \item \textbf{IVSpread}: Difference between the near ATM put (delta = -0.5 and maturity = 30 days) and call (delta = 0.5 and maturity = 30 days) implied volatility, using the last daily observation of each month, following \citet{yanJumpRiskStock2011} and \citet{baliVolatilitySpreadsExpected2009}.
    \item \textbf{IVSkew}: Difference between the Out-The-Money (OTM) put implied volatility with moneyness closest to but above 1, and the OTM call implied volatility with moneyness closest to but below 1, using options with expiration between 10 and 60 days, following \citet{xingWhatDoesIndividual2010}.
    \item \textbf{VOV}: Volatility of option-implied volatility, calculated as the normalized standard deviation of daily implied volatility of near ATM options (delta = 0.5 for calls and delta = -0.5 for puts) with maturity of 30 days \citep{baltussenUnknownUnknownsUncertainty2018}. Each month, the mean and standard deviation of daily IV are calculated, and VOV is defined as the standard deviation divided by the mean.
        \begin{align*}
            \text{VOV}_t = 0.5 * \left(\frac{\sigma(IV_{call, t})}{\mu(IV_{call, t})} + \frac{\sigma(IV_{put, t})}{\mu(IV_{put, t})}\right)
        \end{align*}
    \item \textbf{IVol-RVol}: Difference between option-implied volatility and realized volatility, following \citet{baliVolatilitySpreadsExpected2009}. Realized volatility is calculated using daily stock returns over the past 30 calendar days, and implied volatility is the near ATM IV with maturity of 30 days, average across call and put options.
\end{itemize}

Besides these option-based characteristics, we also include the following commonly used stock characteristics as control variables in the empirical tests: 
\begin{itemize}
    \item \textbf{log(ME)}: Logarithm of market capitalization, the product of stock price and number of shares outstanding.
    \item \textbf{log(B/M)}: Logarithm of book to market ratio following \citet{famaCrossSectionExpectedStock1992}.
    \item \textbf{Inv}: Annual growth rate of total asset following \citet{cooperAssetGrowthCrossSection2008}.
    \item \textbf{Profit}: Operating profitability, adjusted for R\&D expenses, following \citet{ballAccrualsCashFlows2016}.
    \item \textbf{Illiq}: \citet{amihudIlliquidityStockReturns2002} illiquidity measure, calculated as the past twelve-month average of absolute daily stock return divided by daily dollar trading volume.
    \item \textbf{Ivol}: Idiosyncratic volatility following \citet{angCrossSectionVolatilityExpected2006}, calculated as the standard deviation of residuals from Fama-French three factor model over the past month daily data.
    \item $\beta$: CAPM beta calculated using the historical daily returns over a 252-trading-day estimation window and a 126-trading-day minimum requirement, provided by the Beta Suite by WRDS\footnote{\url{https://wrds-www.wharton.upenn.edu/pages/get-data/beta-suite-wrds/}}.
    \item $ret_{1, 0}$: Short-term reversal, calculated as the stock return over the previous month \citep{jegadeeshEvidencePredictableBehavior1990}.
    \item $ret_{12, 2}$: Momentum, calculated as the stock return over the past 11 months, skipping the most recent month ($t-2$ to $t-12$), following \citet{jegadeeshReturnsBuyingWinners1993a}.
\end{itemize}

\clearpage
\section{Additional Results} \label{sec:appendixc}
%\addcontentsline{toc}{section}{Appendix C}
\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{4pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Portfolio Analysis, Binary Classification Model, Non-Micro Stocks}
\label{tab:portfolio_binary_nm}
\begin{threeparttable}
\input{Tables/portfolio_binary_models_nm.tex}
\begin{tablenotes}
    \footnotesize
    \item Note: $^{***} p < 0.01$; $^{**} p < 0.05$; $^{*} p < 0.1$
\end{tablenotes}
\end{threeparttable}
\end{table}


% \begin{table}[htbp]
% \centering
% \small
% \setlength{\tabcolsep}{4pt}
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Portfolio Analysis, Binary Classification Model, S\&P 500 Stocks}
% \label{tab:portfolio_binary_micro}
% \begin{threeparttable}
% \input{Tables/portfolio_binary_sp.tex}
% \end{threeparttable}
% \end{table}


\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{4pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Time Series Regression, Binary Classification Model, Non-Micro Stocks}
\label{tab:ts_reg_binary_nm}
\begin{threeparttable}
\resizebox{\textwidth}{!}{\input{Tables/ts_reg_binary_models_nm.tex}}
\end{threeparttable}
\end{table}

% \begin{table}[htbp]
% \centering
% \small
% \setlength{\tabcolsep}{4pt}
% \sisetup{
%     table-align-text-post=false,
%     input-symbols = {(),-},
%     table-space-text-pre = {(},
%     table-space-text-post = {)} 
% }
% \caption{Time Series Regression, Binary Classification Model, S\&P 500 Stocks}
% \label{tab:ts_reg_binary_large}
% \begin{threeparttable}
% \resizebox{\textwidth}{!}{\input{Tables/ts_reg_binary_sp.tex}}
% \end{threeparttable}
% \end{table}

\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{6pt}
\sisetup{
    table-align-text-post=false,
    input-symbols = {(),-},
    table-space-text-pre = {(},
    table-space-text-post = {)} 
}
\caption{Fama-MacBeth Regression, Binary Classification Model, Non-Micro Stocks}
\label{tab:fm_reg_binary_nm}
\begin{threeparttable}
\input{Tables/fm_reg_binary_models_nm.tex}
\end{threeparttable}
\end{table}




\end{document}